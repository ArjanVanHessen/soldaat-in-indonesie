{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zoeken op basis van Text & Data Mining\n",
    "\n",
    "\n",
    "## 1. installeren en importeren van modules\n",
    "\n",
    "In dit tutorial vind je uitleg over hoe je het corpus van \"Soldaat in Indonesie\" kunt doorzoeken op basis van Text & Data Mining. Er wordt hierbij gebruik gemaakt van de programmeertaal Python. Dit tutorial is echter geen basisintroductie tot programmeren in Python. De voorbeelden hieronder laten alleen zien hoe je het corpus kunt doorzoeken met behulp van bestaande modules en bibliotheken. Modules zijn kant en klare en herbruikbare ‘pakketjes’ code waarin specifieke functionaliteiten worden aangeboden. De meeste modules zijn generiek, en kunnen dus op verschillende datasets worden toegepast.\n",
    "\n",
    "Voordat je van deze modules gebruik kunt maken moet je ze eerst installeren. Je kunt dit vergelijken met het installeren van een nieuw programma op je computer. Na de installatie van deze modules worden alle functionaliteiten die hierin worden geboden beschikbaar binnen de nieuwe code die je wilt gaan schijven. Modules en bibliotheken kunnen via de onderstaande commando's worden geinstalleerd. Plaats de cursor in de onderstaande cel staan, en klik daarna op [shift] + [Enter]. Hierna verschijnen er, als het goed is, een aantal meldingen over het installatieproces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} os\n",
    "!conda install --yes --prefix {sys.prefix} nltk\n",
    "!conda install --yes --prefix {sys.prefix} wordcloud\n",
    "!conda install --yes --prefix {sys.prefix} matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In dit tutorial wordt onder meer gebruik gemaakt van de module ‘os’. Deze module biedt een aantal functies waarmee je contact kunt maken met het besturingssysteem van je computer (de letters in 'os' staan voor 'operating system'). Met de functies in deze module kun je onder meer de inhoud van een map op je computer lezen. \n",
    "\n",
    "'nltk' is een verzameling modules die je kunt gebruiken bij analyses op het gebied van Natural Language Processing. Zo kun je paragrafen op laten splitsen in afzonderlijke zinnen, je kunt de stam van een woord of een werkwoord vinden, en je kunt de computer vragen om grammaticale categorieën toe te voegen aan woorden.\n",
    "\n",
    "Als alle modules correct zijn geinstalleerd kunnen deze worden geimporteerd. Zo'n import zorgt er vervolgens voor dat alle functies van deze modules ook in de nieuwe te schrijven code gebruikt kunnen worden. De import zelf geeft, als alle modules goed zijn geinstalleerd, geen meldingen. Je kunt dit vergelijken met het openen van een programma of een app. Als de installatie goed gelukt is, kun je het programma zonder problemen of zonder foutmeldingen openen. \n",
    "\n",
    "Plaats de cursor in de onderstaande cel staan, en klik daarna op [shift] + [Enter]. Als alle modules goed zijn geinstalleerd verschijnen er hierna geen meldingen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import isfile, join , isdir\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib.pyplot as plt\n",
    "from kitlvTdm import *\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De module ‘kitlvTdm’ is specifiek ontwikkeld voor dit KITLV corpus van memoires en bevat een aantal basisoperaties op het gebied van Text & Data Mining.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Zoeken naar een specifieke term\n",
    "\n",
    "De onderstaande code laat zien hoe je op zoek kunt gaan naar egodocumenten die een bepaald trefwoord bevatten. Het woord dat gezocht moet worden moet worden opgegeven als waarde van de variable '*searchTerm*'. De waarde van de variabele '*searchTerm*', tussen de twee aanhalingstekens, kan worden aangepast. \n",
    "\n",
    "Er wordt in de onderstaande code gebruik gemaakt van de module 're', waarmee je kunt zoeken naar zogenaamde reguliere expressies of woordpatronen. Wanneer de code wordt uitgevoerd toont het programma een lijst van alle documenten waar de opgegeven term die in voorkomt, samen met alle gevonden passages. De grootte van deze passages kan worden bepaald met de variabele 'window'. Het getal dat wordt opgegeven bepaalt het aantal woorden voorafgaand aan en volgend op de gebruikte term.\n",
    "\n",
    "Tijdens het digitaliseren van de egocumenten in het corpus van 'Soldaat in Indonesië' hebben alle documenten een eigen numerieke code gekregen. Deze codes zijn ook gebruikt in de bestandsnamen. De functie '*showTitle()*', in de module kitlvTdm, zoekt de volledige titles bij deze documentcodes. Er wordt hierbij gebruik gemaakt van een bestand met de naam '*metadata.csv*'. Dat bestand staat in de zelfde map als het corpus en als dit bestand, de notebook met code en instructies. \n",
    "\n",
    "Deze specifieke vorm van tekstanalyse wordt ook wel 'concordantie' genoemd. Een andere veelgebruikte term is 'keywords in context' (KWIC). \n",
    "\n",
    "Voer de voorbeeldoefening uit door in onderstaande cel dubbel te klikken, en vervolgens op [Shift] + [Enter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'corpus'\n",
    "searchTerm = 'baboe'\n",
    "window = 4\n",
    "\n",
    "for file in os.listdir( dir ):\n",
    "    if re.search( '[.]txt$' , file ):\n",
    "        \n",
    "        book = open( join( dir , file ) )\n",
    "        if re.search( searchTerm , book.read() , re.IGNORECASE ):\n",
    "            title = showTitle(file)\n",
    "            printmd(\"<span style='font-weight: bold; color:#6b0617; '>Occurrences in {} ({})</span>\".format( title , file ))\n",
    "\n",
    "            matches = concordance( join( dir , file ) , searchTerm , window )\n",
    "            for match in matches:\n",
    "                print(' ... {} ... \\n'.format( match ) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vervang de waarde van de variabele 'searchTerm' met een zoekterm die mogelijk van belang is voor je eigen onderzoek. Probeer ook de waarde van de variabele 'window' te variëren. Als je uit de context wilt kunnen opmaken hoe de betekenis van de term bedoeld is, is het raadzaam minstens 30 woorden er voor en er na te kiezen. Ga weer in de cel staan en klik vervolgens op [Shift] + [Enter]. Je hoeft de eerdere resultaten  niet te wissen. Deze worden vanzelf overschreven."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Collocatie\n",
    "\n",
    "Net als bij een concordantie (zie hierboven) richt een collocatie-analyse zich op de context van specifieke zoektermen. Alleen worden bij een collocatie-analyse alle woorden in de context geteld. Op deze manier kan er een numeriek beeld ontstaan van de woorden die veel in de omgeving van een specifieke zoekterm worden gebruikt. \n",
    "\n",
    "We gaan hier weer in het hele corpus zoeken naar de frequentie van woorden voor en na de term. 'searchTerm' is de term waarnaar wordt gezocht, en 'window' bepaalt het aantal woorden voor en na de opgegeven zoekterm. De analyse wordt beperkt tot een specifieke periode. De start van deze periode wordt aangegeven via de variable 'start', en het einde door de variabele 'end'. De onderstaande code berekent allen collocaties voor de egodocumenten die tijdens de genoemde periode zijn gepubliceerd. \n",
    "\n",
    "'*searchTerm*' is de term waarnaar wordt gezicht, en '*window*' bepaalt het aantal woorden voor en na de opgegeven zoekterm. \n",
    "\n",
    "In de onderstaande code wordt ook de functie '_removeStopwords()_' gebruikt. Deze functie heeft als effect dat veelvoorkomende woorden zonder veel betekenis (lidwoorden, voornaamwoorden, voorzetstel) buiten beschouwing worden gelaten. De frequenties van dit soort woorden zijn waarschijnijk weinig betekenisvol.\n",
    "\n",
    "Ga in de cel staan en klik weer op [Shift] + [Enter]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 1945\n",
    "end = 1947\n",
    "\n",
    "dir = 'corpus'\n",
    "searchTerm = 'baboe'\n",
    "window = 30\n",
    "\n",
    "corpusFreq = dict()\n",
    "\n",
    "for file in os.listdir( dir ):\n",
    "    if re.search( '[.]txt$' , file ):\n",
    "        if showYear( file ) is not None:\n",
    "            year = int(showYear( file ) )\n",
    "            if year >= start and year <= end:\n",
    "                print( file + ' (' + str(year) + ')' )\n",
    "                freq = collocation( join( dir , file ) , searchTerm , window )\n",
    "                freq = removeStopwords( freq )\n",
    "                corpusFreq.update(freq)\n",
    "        \n",
    "        \n",
    "freq.clear()\n",
    "freq.update( removeStopwords( corpusFreq ) )        \n",
    "\n",
    "\n",
    "def sortedByValue( dict ):\n",
    "    return sorted( dict , key=lambda x: dict[x])\n",
    "\n",
    "max = 30\n",
    "i = 0\n",
    "\n",
    "\n",
    "print( f'The following words are used most frequently in the vicinity of \"{ searchTerm }\": \\n' )\n",
    "\n",
    "for f in reversed( sortedByValue( freq ) ):\n",
    "    i += 1\n",
    "    print( '{} =>  {}'.format( f , freq[f] ) )\n",
    "    if i == max:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voer nu samen een collocatie-analyse uit, aan de hand van een zoekterm die van belang kan zijn voor jullie onderzoek. Experimenteer met verschilende waarden voor de variabelen 'searchTerm', en 'window'\n",
    "\n",
    "Bespreek het resultaat met je buurman of -vrouw, en bedenk aan welke voorwaarden de zoekactie moet voldoen om betekenisvol te zijn voor jouw bronnenonderzoek. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Woordfrequenties\n",
    "\n",
    "\n",
    "Welke woorden komen het meeste voor in het corpus? De onderstaande code berekent de frequenties van alle woorden in de tekst die wordt genoemd in de variabele 'egodocument'. Deze code maakt net als bovenstaande code gebruik van de functie '_removeStopWords()_'.\n",
    "\n",
    "De analyse kan worden toegespitst op een specifieke periode. In de onderstaande code geeft de variabele 'start' het begin van de periode aan, en de variabele 'end' het einde. De code berekent alleen de woordfrequenties in de documenten die gepubliceerd zijn binnen de periode die op deze manier is vastgelegd. \n",
    "\n",
    "De code toont bovendien uitsluitend de 30 meest frequente termen. Het aantal termen dat wordt geprint wordt bepaald door de variabele '*max*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = 1945\n",
    "end = 1947\n",
    "\n",
    "dir = 'corpus'\n",
    "\n",
    "corpusFreq = dict()\n",
    "\n",
    "print('The following egodocuments were published during the specified period:\\n')\n",
    "\n",
    "for file in os.listdir( dir ):\n",
    "    if re.search( '[.]txt$' , file ):\n",
    "        if showYear( file ) is not None:\n",
    "            year = int(showYear( file ) )\n",
    "            if year >= start and year <= end:\n",
    "                print( file + ' (' + str(year) + ')' )\n",
    "                freq = calculateWordFrequencies( join( dir , file ) )\n",
    "                freq = removeStopwords( freq )\n",
    "                corpusFreq.update(freq)\n",
    "\n",
    "freq.clear()\n",
    "freq.update( removeStopwords( corpusFreq ) )  \n",
    "\n",
    "def sortedByValue( dict ):\n",
    "    return sorted( dict , key=lambda x: dict[x])\n",
    "\n",
    "max = 100\n",
    "i = 0\n",
    "\n",
    "\n",
    "print( '\\nThe following words occur most frequently in the corpus in between {} and {}.\\n'.format( start , end ) )\n",
    "\n",
    "for f in reversed( sortedByValue( freq ) ):\n",
    "    i += 1\n",
    "    print( '{} =>  {}'.format( f , freq[f] ) )\n",
    "    if i == max:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bepaal de meest frequente woorden in een van specifiek onderdeel van het corpus van \"Soldaat in Indonesie\", door te experimenteren met verschilende waarden voor de variabelen '*start*', '*end*' en '*max*'.\n",
    "\n",
    "Als de bovenstaande code is uitgevoerd kunnen de gevonden woorden met de code die hieronder staat worden wergegeven als een *word cloud*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "wordcloud = WordCloud( background_color=\"white\",  width=3000,height=1500, max_words= 100,relative_scaling=1,normalize_plurals=False).generate_from_frequencies( corpusFreq )\n",
    "\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De onderstaande code slaa de wordcloud op als een bestand. De naam wordt opgegegeven in de variabele met de naam '*naamOutFile*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naamOutFile = '45-47.jpg'\n",
    "\n",
    "wordcloud = WordCloud( background_color=\"white\",  width=3000,height=1500, max_words= 100,relative_scaling=1,normalize_plurals=False).generate_from_frequencies( corpusFreq )\n",
    "\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.savefig( naamOutFile )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Het maken van een export\n",
    "\n",
    "In de code die tot nu toe is besproken worden de resultaten van de code simpelweg getoond in dit notebook. Het kan uiteraard ook nuttig zijn om de resutaten te exporteren naar een tekstbestand, zodat deze resultaten dan ook weer in andere programma's kunnen worden bekeken of worden geanayseerd. \n",
    "\n",
    "In de onderstaande code worden de resultaten van de concordantie-analyse en van de frequentie-analyse weggeschreven als tekstbestanden. De bestanden worden aangemaakt op dezelfde plaats als waar dit notebook is opgeslagen. De bestandsnamen worden bepaald door de variabelen 'out1' en out2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = 'concordantie.txt'\n",
    "\n",
    "\n",
    "### Bestand 1\n",
    "\n",
    "outFile = open( out1 , 'w')\n",
    "\n",
    "dir = 'corpus'\n",
    "searchTerm = 'baboe'\n",
    "window = 4\n",
    "\n",
    "for file in os.listdir( dir ):\n",
    "    if re.search( '[.]txt$' , file ):\n",
    "        \n",
    "        book = open( join( dir , file ) )\n",
    "        if re.search( searchTerm , book.read() , re.IGNORECASE ):\n",
    "            title = showTitle(file)\n",
    "            \n",
    "            outFile.write( '\\n\\nOccurrences in {} ({}):\\n\\n'.format( title , file ) )\n",
    "\n",
    "            matches = concordance( join( dir , file ) , searchTerm , window )\n",
    "            for match in matches:\n",
    "                outFile.write( '...' + match + '...\\n')\n",
    "\n",
    "\n",
    "print('De resultaten zijn weggeschreven in een bestand met de naam \"concordantie.txt\"')\n",
    "outFile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out2 = 'frequentie.csv'\n",
    "outFile = open( out2 , 'w')\n",
    "\n",
    "egodocument = '03391.txt'\n",
    "\n",
    "freq = calculateWordFrequencies( join( dir , egodocument ) )\n",
    "freq = removeStopwords( freq )\n",
    "\n",
    "sorted_f = sorted( freq , key=lambda x: freq[x])\n",
    "max = 30\n",
    "i = 0\n",
    "\n",
    "outFile.write( 'term,frequency\\n' )\n",
    "\n",
    "\n",
    "for f in reversed( sorted_f ):\n",
    "    i += 1\n",
    "    outFile.write( '{},{}\\n'.format( f , freq[f] ) )\n",
    "    if i == max:\n",
    "        break\n",
    "        \n",
    "        \n",
    "print(f'De resultaten zijn weggeschreven in een bestand met de naam {out2}')\n",
    "      \n",
    "outFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probeer twee exports te maken van onderzoeksdata die relevant lijken voor jouw onderzoek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
