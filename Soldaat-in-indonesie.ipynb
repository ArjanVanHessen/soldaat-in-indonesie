{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zoeken op basis van Text & Data Mining\n",
    "\n",
    "\n",
    "## 1. installeren en importeren van modules\n",
    "\n",
    "In dit tutorial vind je uitleg over hoe je het corpus van \"Soldaat in Indonesie\" kunt doorzoeken op basis van Text & Data Mining. Er wordt hierbij gebruik gemaakt van de programmeertaal Python. Dit tutorial is echter geen basisintroductie tot programmeren in Python. De voorbeelden hieronder laten alleen zien hoe je het corpus kunt doorzoeken met behulp van bestaande modules en bibliotheken. Modules zijn kant en klare en herbruikbare ‘pakketjes’ code waarin specifieke functionaliteiten worden aangeboden. De meeste modules zijn generiek, en kunnen dus op verschillende datasets worden toegepast.\n",
    "\n",
    "Voordat je van deze modules gebruik kunt maken moet je ze eerst installeren. Je kunt dit vergelijken met het installeren van een nieuw programma op je computer. Na de installatie van deze modules worden alle functionaliteiten die hierin worden geboden beschikbaar binnen de nieuwe code die je wilt gaan schijven. Modules en bibliotheken kunnen via de onderstaande commando's worden geinstalleerd. Plaats de cursor in de onderstaande cel staan, en klik daarna op [shift] + [Enter]. Hierna verschijnen er, als het goed is, een aantal meldingen over het installatieproces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} os\n",
    "!conda install --yes --prefix {sys.prefix} nltk\n",
    "!conda install --yes --prefix {sys.prefix} wordcloud\n",
    "!conda install --yes --prefix {sys.prefix} wordCloud\n",
    "!conda install --yes --prefix {sys.prefix} matplotlib\n",
    "\n",
    "!{sys.executable} -m pip install wordcloud\n",
    "!{sys.executable} -m pip install wordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In dit tutorial wordt onder meer gebruik gemaakt van de module ‘os’. Deze module biedt een aantal functies waarmee je contact kunt maken met het besturingssysteem van je computer (de letters in 'os' staan voor 'operating system'). Met de functies in deze module kun je onder meer de inhoud van een map op je computer lezen. \n",
    "\n",
    "'nltk' is een verzameling modules die je kunt gebruiken bij analyses op het gebied van Natural Language Processing. Zo kun je paragrafen op laten splitsen in afzonderlijke zinnen, je kunt de stam van een woord of een werkwoord vinden, en je kunt de computer vragen om grammaticale categorieën toe te voegen aan woorden.\n",
    "\n",
    "Als alle modules correct zijn geinstalleerd kunnen deze worden geimporteerd. Zo'n import zorgt er vervolgens voor dat alle functies van deze modules ook in de nieuwe te schrijven code gebruikt kunnen worden. De import zelf geeft, als alle modules goed zijn geinstalleerd, geen meldingen. Je kunt dit vergelijken met het openen van een programma of een app. Als de installatie goed gelukt is, kun je het programma zonder problemen of zonder foutmeldingen openen. \n",
    "\n",
    "Plaats de cursor in de onderstaande cel staan, en klik daarna op [shift] + [Enter]. Als alle modules goed zijn geinstalleerd verschijnen er hierna geen meldingen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import isfile, join , isdir\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib.pyplot as plt\n",
    "from kitlvTdm import *\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De module ‘kitlvTdm’ is specifiek ontwikkeld voor dit KITLV corpus van memoires en bevat een aantal basisoperaties op het gebied van Text & Data Mining.\n",
    "\n",
    "Let erop dat het corpus met alle gedigitaliseerde egodocumenten moet worden opgeslagen in de map waar ook dit Notebook staat. Een-zip bestand met alle teksten kan worden gedownload via de volgende URL:\n",
    "\n",
    "https://surfdrive.surf.nl/files/index.php/s/IFb16WXK8pIjuDs\n",
    "\n",
    "Na het downloaden van het ZIP-bestand moet de map ook worden uitgepakt. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Zoeken naar een specifieke term\n",
    "\n",
    "De onderstaande code laat zien hoe je op zoek kunt gaan naar egodocumenten die een bepaald trefwoord bevatten. Het woord dat gezocht moet worden moet worden opgegeven als waarde van de variable '*searchTerm*'. De waarde van de variabele '*searchTerm*', tussen de twee aanhalingstekens, kan worden aangepast. \n",
    "\n",
    "Er wordt in de onderstaande code gebruik gemaakt van de module 're', waarmee je kunt zoeken naar zogenaamde reguliere expressies of woordpatronen. Wanneer de code wordt uitgevoerd toont het programma een lijst van alle documenten waar de opgegeven term die in voorkomt, samen met alle gevonden passages. De grootte van deze passages kan worden bepaald met de variabele 'window'. Het getal dat wordt opgegeven bepaalt het aantal woorden voorafgaand aan en volgend op de gebruikte term.\n",
    "\n",
    "Tijdens het digitaliseren van de egocumenten in het corpus van 'Soldaat in Indonesië' hebben alle documenten een eigen numerieke code gekregen. Deze codes zijn ook gebruikt in de bestandsnamen. De functie '*showTitle()*', in de module kitlvTdm, zoekt de volledige titles bij deze documentcodes. Er wordt hierbij gebruik gemaakt van een bestand met de naam '*metadata.csv*'. Dat bestand staat in de zelfde map als het corpus en als dit bestand, de notebook met code en instructies. \n",
    "\n",
    "Deze specifieke vorm van tekstanalyse wordt ook wel 'concordantie' genoemd. Een andere veelgebruikte term is 'keywords in context' (KWIC). \n",
    "\n",
    "Voer de voorbeeldoefening uit door in onderstaande cel dubbel te klikken, en vervolgens op [Shift] + [Enter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'corpus'\n",
    "searchTerm = 'baboe'\n",
    "window = 4\n",
    "\n",
    "for file in os.listdir( dir ):\n",
    "    if re.search( '[.]txt$' , file ):\n",
    "        \n",
    "        book = open( join( dir , file ) )\n",
    "        if re.search( searchTerm , book.read() , re.IGNORECASE ):\n",
    "            title = showTitle(file)\n",
    "            printmd(\"<span style='font-weight: bold; color:#6b0617; '>Occurrences in {} ({})</span>\".format( title , file))\n",
    "\n",
    "            matches = concordance( join( dir , file ) , searchTerm , window )\n",
    "            for match in matches:\n",
    "                print(' ... {} ... \\n'.format( match ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vervang de waarde van de variabele 'searchTerm' met een zoekterm die mogelijk van belang is voor je eigen onderzoek. Probeer ook de waarde van de variabele 'window' te variëren. Als je uit de context wilt kunnen opmaken hoe de betekenis van de term bedoeld is, is het raadzaam minstens 30 woorden er voor en er na te kiezen. Ga weer in de cel staan en klik vervolgens op [Shift] + [Enter]. Je hoeft de eerdere resultaten  niet te wissen. Deze worden vanzelf overschreven.\n",
    "\n",
    "De resultaten kunnen naar een tekst-bestand worden geexporteerd via de onderstaande code. De bestandsnaam wordt bepaald door de variabele '*outFile*'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'corpus'\n",
    "searchTerm = 'baboe'\n",
    "window = 4\n",
    "\n",
    "\n",
    "outFile = 'concordantieExport.txt'\n",
    "out = open( outFile , 'w' )\n",
    "\n",
    "\n",
    "\n",
    "for file in os.listdir( dir ):\n",
    "    if re.search( '[.]txt$' , file ):\n",
    "        \n",
    "        book = open( join( dir , file ) )\n",
    "        if re.search( searchTerm , book.read() , re.IGNORECASE ):\n",
    "            title = showTitle(file)\n",
    "            out.write(\"Occurrences in {} ({})\\n\".format( title , file ))\n",
    "\n",
    "            matches = concordance( join( dir , file ) , searchTerm , window )\n",
    "            for match in matches:\n",
    "                out.write(' ... {} ... \\n'.format( match ) )\n",
    "\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Collocatie\n",
    "\n",
    "Net als bij een concordantie (zie hierboven) richt een collocatie-analyse zich op de context van specifieke zoektermen. Alleen worden bij een collocatie-analyse alle woorden in de context geteld. Op deze manier kan er een numeriek beeld ontstaan van de woorden die veel in de omgeving van een specifieke zoekterm worden gebruikt. \n",
    "\n",
    "We gaan hier weer in het corpus zoeken naar de frequentie van woorden voor en na de term. 'searchTerm' is de term waarnaar wordt gezocht, en 'window' bepaalt het aantal woorden voor en na de opgegeven zoekterm. De analyse wordt beperkt tot een specifieke periode. De start van deze periode wordt aangegeven via de variable 'start', en het einde door de variabele 'end'. De onderstaande code berekent allen collocaties voor de egodocumenten die tijdens de genoemde periode zijn gepubliceerd. \n",
    "\n",
    "'*searchTerm*' is de term waarnaar wordt gezicht, en '*window*' bepaalt het aantal woorden voor en na de opgegeven zoekterm. \n",
    "\n",
    "In de onderstaande code wordt ook de functie '_removeStopwords()_' gebruikt. Deze functie heeft als effect dat veelvoorkomende woorden zonder veel betekenis (lidwoorden, voornaamwoorden, voorzetstel) buiten beschouwing worden gelaten. De frequenties van dit soort woorden zijn waarschijnijk weinig betekenisvol.\n",
    "\n",
    "Ga in de cel staan en klik weer op [Shift] + [Enter]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 1945\n",
    "end = 1947\n",
    "\n",
    "dir = 'corpus'\n",
    "searchTerm = 'baboe'\n",
    "window = 30\n",
    "\n",
    "corpusFreq = dict()\n",
    "\n",
    "for file in os.listdir( dir ):\n",
    "    if re.search( '[.]txt$' , file ):\n",
    "        if showYear( file ) is not None:\n",
    "            year = int(showYear( file ) )\n",
    "            if year >= start and year <= end:\n",
    "                print( file + ' (' + str(year) + ')' )\n",
    "                freq = collocation( join( dir , file ) , searchTerm , window )\n",
    "                freq = removeStopwords( freq )\n",
    "                corpusFreq.update(freq)\n",
    "        \n",
    "        \n",
    "freq.clear()\n",
    "freq.update( removeStopwords( corpusFreq ) )        \n",
    "\n",
    "\n",
    "def sortedByValue( dict ):\n",
    "    return sorted( dict , key=lambda x: dict[x])\n",
    "\n",
    "max = 30\n",
    "i = 0\n",
    "\n",
    "if len(freq)> 0:\n",
    "\n",
    "    print( f'The following words are used most frequently in the vicinity of \"{ searchTerm }\": \\n' )\n",
    "\n",
    "    for f in reversed( sortedByValue( freq ) ):\n",
    "        i += 1\n",
    "        print( '{} =>  {}'.format( f , freq[f] ) )\n",
    "        if i == max:\n",
    "            break\n",
    "            \n",
    "else:\n",
    "    print('\\n\\nThe search term you provided does not occur in the documents published during the selected period.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voer nu samen een collocatie-analyse uit, aan de hand van een zoekterm die van belang kan zijn voor jullie onderzoek. Experimenteer met verschilende waarden voor de variabelen 'searchTerm', en 'window'\n",
    "\n",
    "Bespreek het resultaat met je buurman of -vrouw, en bedenk aan welke voorwaarden de zoekactie moet voldoen om betekenisvol te zijn voor jouw bronnenonderzoek. \n",
    "\n",
    "De gevonden worden kunnen worden geëxporteerd via de onderstaande code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outFile = 'collocation.csv'\n",
    "out = open( outFile , 'w' )\n",
    "\n",
    "out.write('term,frequency\\n')\n",
    "\n",
    "for f in reversed( sortedByValue( freq ) ):\n",
    "    i += 1\n",
    "    out.write( '{},{}\\n'.format( f , freq[f] ) )\n",
    "    if i == max:\n",
    "        break\n",
    "        \n",
    "out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Woordfrequenties\n",
    "\n",
    "\n",
    "Welke woorden komen het meeste voor in het corpus? De onderstaande code berekent de frequenties van alle woorden in de tekst die wordt genoemd in de variabele 'egodocument'. Deze code maakt net als bovenstaande code gebruik van de functie '_removeStopWords()_'.\n",
    "\n",
    "De analyse kan worden toegespitst op een specifieke periode. In de onderstaande code geeft de variabele 'start' het begin van de periode aan, en de variabele 'end' het einde. De code berekent alleen de woordfrequenties in de documenten die gepubliceerd zijn binnen de periode die op deze manier is vastgelegd. \n",
    "\n",
    "De code toont bovendien uitsluitend de 30 meest frequente termen. Het aantal termen dat wordt geprint wordt bepaald door de variabele '*max*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = 1945\n",
    "end = 1946\n",
    "\n",
    "dir = 'corpus'\n",
    "\n",
    "corpusFreq = dict()\n",
    "\n",
    "print('The following egodocuments were published during the specified period:\\n')\n",
    "\n",
    "for file in os.listdir( dir ):\n",
    "    if re.search( '[.]txt$' , file ):\n",
    "        if showYear( file ) is not None:\n",
    "            year = int(showYear( file ) )\n",
    "            if year >= start and year <= end:\n",
    "                print( file + ' (' + str(year) + ')' )\n",
    "                freq = calculateWordFrequencies( join( dir , file ) )\n",
    "                freq = removeStopwords( freq )\n",
    "                corpusFreq.update(freq)\n",
    "\n",
    "freq.clear()\n",
    "freq.update( removeStopwords( corpusFreq ) )  \n",
    "\n",
    "def sortedByValue( dict ):\n",
    "    return sorted( dict , key=lambda x: dict[x])\n",
    "\n",
    "max = 500\n",
    "i = 0\n",
    "\n",
    "\n",
    "print( '\\nThe following words occur most frequently in the corpus in between {} and {}.\\n'.format( start , end ) )\n",
    "\n",
    "for f in reversed( sortedByValue( freq ) ):\n",
    "    i += 1\n",
    "    print( '{} =>  {}'.format( f , freq[f] ) )\n",
    "    if i == max:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bepaal de meest frequente woorden in een van specifiek onderdeel van het corpus van \"Soldaat in Indonesie\", door te experimenteren met verschilende waarden voor de variabelen '*start*', '*end*' en '*max*'.\n",
    "\n",
    "Als de bovenstaande code is uitgevoerd kunnen de gevonden woorden met de code die hieronder staat worden wergegeven als een *word cloud*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "aantalWoorden = 60\n",
    "\n",
    "wordcloud = WordCloud( background_color=\"white\",  width=600,height=500, max_words= aantalWoorden,relative_scaling=1,normalize_plurals=False).generate_from_frequencies( freq )\n",
    "\n",
    "fig = plt.figure( figsize=(10,10) )\n",
    "\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De onderstaande code slaat de wordcloud op als een bestand. De naam wordt opgegegeven in de variabele met de naam '*naamOutFile*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naamOutFile = 'frequencies.jpg'\n",
    "\n",
    "aantalWoorden = 80\n",
    "\n",
    "wordcloud = WordCloud( background_color=\"white\",  width=600,height=500, max_words= aantalWoorden,relative_scaling=1,normalize_plurals=False).generate_from_frequencies( freq )\n",
    "\n",
    "fig = plt.figure( figsize=(10,10) )\n",
    "\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "\n",
    "plt.savefig( naamOutFile )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Combinaties van verwijzingen naar Molukkers en verwijzingen naar geweld\n",
    "\n",
    "De onderstaande code is ontwikkeld om op zoek te gaan naar passages waarin geweldsdaden worden beschreven van Molukse en ook andere Indonesische militairen die aan Nederlandse zijde meevochten, veelal in het Koninklijk Nederlands-Indisch Leger (KNIL). \n",
    "\n",
    "Om deze passages te vinden is op de eerste plaats gebruik gemaakt van een lijst met termen die duiden op het gebruik van geweld. Deze lijst is op het volgende adres te vinden: \n",
    "\n",
    "https://raw.githubusercontent.com/peterverhaar/soldaat-in-indonesie/master/geweld.txt\n",
    "\n",
    "Hierbij is gewerkt met de aanname dat, wanneer een paragraaf veel woorden van deze lijst bevat, het waarschijnlijk is dat er een geweldsdaad wordt beschreven. \n",
    "\n",
    "De lijst met passages is hiernaast op een tweede manier gefilterd. Het tekstfragment moet ook een verwijzing bevatten naar Molukse of andere Indonesische militairen. Er wordt hierbij gebruik gemaakt van een reguliere expressie, een tekstpatroon waarin de gelijktijdig naar verschillende naamsvarianten en spellingswijzen kan worden gezocht. \n",
    "\n",
    "`regex = r'((molukker\\\\w*)|(moluks\\\\w*)|(ambonn?ees\\\\w*)|((ambonn?ezen))|(menadonees(ch)?)|(menadonezen?)|(minahasa))'`\n",
    "\n",
    "De gevonden passages worden weggeschreven in een bestand met de naam 'gevondenPassages.txt'. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03390.txt\n",
      "03391.txt\n",
      "03392.txt\n",
      "03393.txt\n",
      "03394.txt\n",
      "03395.txt\n",
      "03396.txt\n",
      "03398.txt\n",
      "03399.txt\n",
      "03400.txt\n",
      "03401.txt\n",
      "03402.txt\n",
      "03403.txt\n",
      "03404.txt\n",
      "03405.txt\n",
      "03406.txt\n",
      "03407.txt\n",
      "03408.txt\n",
      "03409.txt\n",
      "03410.txt\n",
      "03411.txt\n",
      "03412.txt\n",
      "03413.txt\n",
      "03414.txt\n",
      "03415.txt\n",
      "03416.txt\n",
      "03417.txt\n",
      "03418.txt\n",
      "03419.txt\n",
      "03420.txt\n",
      "03421.txt\n",
      "03422.txt\n",
      "03423.txt\n",
      "03424.txt\n",
      "03425.txt\n",
      "03426.txt\n",
      "03427.txt\n",
      "03428.txt\n",
      "03429.txt\n",
      "03430.txt\n",
      "03431.txt\n",
      "03432.txt\n",
      "03433.txt\n",
      "03434.txt\n",
      "03435.txt\n",
      "03436.txt\n",
      "03437.txt\n",
      "03438.txt\n",
      "03439.txt\n",
      "03440.txt\n",
      "03441.txt\n",
      "03442.txt\n",
      "03443.txt\n",
      "03444.txt\n",
      "03445.txt\n",
      "03446.txt\n",
      "03447.txt\n",
      "03448.txt\n",
      "03449.txt\n",
      "03450.txt\n",
      "03451.txt\n",
      "03452.txt\n",
      "03453.txt\n",
      "03454.txt\n",
      "03455.txt\n",
      "03456.txt\n",
      "03457.txt\n",
      "03458.txt\n",
      "03459.txt\n",
      "03460.txt\n",
      "03461.txt\n",
      "03462.txt\n",
      "03463.txt\n",
      "03464.txt\n",
      "03465.txt\n",
      "03466.txt\n",
      "03467.txt\n",
      "03468.txt\n",
      "03469.txt\n",
      "03470.txt\n",
      "03471.txt\n",
      "03472.txt\n",
      "03473.txt\n",
      "03474.txt\n",
      "03475.txt\n",
      "03476.txt\n",
      "03477.txt\n",
      "03478.txt\n",
      "03479.txt\n",
      "03480.txt\n",
      "03482.txt\n",
      "03483.txt\n",
      "03484.txt\n",
      "03485.txt\n",
      "03486.txt\n",
      "03487.txt\n",
      "03488.txt\n",
      "03489.txt\n",
      "03490.txt\n",
      "03491.txt\n",
      "03492.txt\n",
      "03493.txt\n",
      "03494.txt\n",
      "03495.txt\n",
      "03496.txt\n",
      "03497.txt\n",
      "03498.txt\n",
      "03499.txt\n",
      "03500.txt\n",
      "03501.txt\n",
      "03502.txt\n",
      "03503.txt\n",
      "03504.txt\n",
      "03505.txt\n",
      "03506.txt\n",
      "03507.txt\n",
      "03508.txt\n",
      "03509.txt\n",
      "03510.txt\n",
      "03511.txt\n",
      "03512.txt\n",
      "03513.txt\n",
      "03514.txt\n",
      "03515.txt\n",
      "03516.txt\n",
      "03517.txt\n",
      "03518.txt\n",
      "03519.txt\n",
      "03520.txt\n",
      "03521.txt\n",
      "03522.txt\n",
      "03523.txt\n",
      "03524.txt\n",
      "03525.txt\n",
      "03526.txt\n",
      "03527.txt\n",
      "03528.txt\n",
      "03529.txt\n",
      "03530.txt\n",
      "03531.txt\n",
      "03532.txt\n",
      "03533.txt\n",
      "03534.txt\n",
      "03535.txt\n",
      "03536.txt\n",
      "03537.txt\n",
      "03538.txt\n",
      "03539.txt\n",
      "03540.txt\n",
      "03541.txt\n",
      "03542.txt\n",
      "03543.txt\n",
      "03544.txt\n",
      "03545.txt\n",
      "03546.txt\n",
      "03547.txt\n",
      "03548.txt\n",
      "03549.txt\n",
      "03550.txt\n",
      "03551.txt\n",
      "03552.txt\n",
      "03553.txt\n",
      "03554.txt\n",
      "03555.txt\n",
      "03556.txt\n",
      "03557.txt\n",
      "03558.txt\n",
      "03559.txt\n",
      "03560.txt\n",
      "03561.txt\n",
      "03562.txt\n",
      "03563.txt\n",
      "03564.txt\n",
      "03565.txt\n",
      "03566.txt\n",
      "03567.txt\n",
      "03568.txt\n",
      "03569.txt\n",
      "03570.txt\n",
      "03571.txt\n",
      "03572.txt\n",
      "03573.txt\n",
      "03574.txt\n",
      "03575.txt\n",
      "03576.txt\n",
      "03577.txt\n",
      "03578.txt\n",
      "03579.txt\n",
      "03580.txt\n",
      "03581.txt\n",
      "03582.txt\n",
      "03583.txt\n",
      "03584.txt\n",
      "03585.txt\n",
      "03586.txt\n",
      "03587.txt\n",
      "03588.txt\n",
      "03589.txt\n",
      "03590.txt\n",
      "03591.txt\n",
      "03592.txt\n",
      "03593.txt\n",
      "03594.txt\n",
      "03595.txt\n",
      "03596.txt\n",
      "03597.txt\n",
      "03598.txt\n",
      "03599.txt\n",
      "03600.txt\n",
      "03601.txt\n",
      "03602.txt\n",
      "03603.txt\n",
      "03604.txt\n",
      "03605.txt\n",
      "03606.txt\n",
      "03607.txt\n",
      "03608.txt\n",
      "03609.txt\n",
      "03610.txt\n",
      "03611.txt\n",
      "03612.txt\n",
      "03613.txt\n",
      "03614.txt\n",
      "03615.txt\n",
      "03616.txt\n",
      "03617.txt\n",
      "03618.txt\n",
      "03619.txt\n",
      "03620.txt\n",
      "03621.txt\n",
      "03622.txt\n",
      "03623.txt\n",
      "03624.txt\n",
      "03625.txt\n",
      "03626.txt\n",
      "03627.txt\n",
      "03628.txt\n",
      "03629.txt\n",
      "03630.txt\n",
      "03631.txt\n",
      "03632.txt\n",
      "03633.txt\n",
      "03634.txt\n",
      "03635.txt\n",
      "03636.txt\n",
      "03637.txt\n",
      "03638.txt\n",
      "03639.txt\n",
      "03640.txt\n",
      "03641.txt\n",
      "03642.txt\n",
      "03643.txt\n",
      "03644.txt\n",
      "03645.txt\n",
      "03646.txt\n",
      "03647.txt\n",
      "03648.txt\n",
      "03649.txt\n",
      "03650.txt\n",
      "03651.txt\n",
      "03652.txt\n",
      "03653.txt\n",
      "03654.txt\n",
      "03655.txt\n",
      "03656.txt\n",
      "03657.txt\n",
      "03658.txt\n",
      "03659.txt\n",
      "03660.txt\n",
      "03661.txt\n",
      "03662.txt\n",
      "03663.txt\n",
      "03664.txt\n",
      "03665.txt\n",
      "03666.txt\n",
      "03667.txt\n",
      "03668.txt\n",
      "03669.txt\n",
      "03670.txt\n",
      "03671.txt\n",
      "03672.txt\n",
      "03673.txt\n",
      "03674.txt\n",
      "03675.txt\n",
      "03676.txt\n",
      "03677.txt\n",
      "03678.txt\n",
      "03679.txt\n",
      "03680.txt\n",
      "03681.txt\n",
      "03682.txt\n",
      "03683.txt\n",
      "03684.txt\n",
      "03685.txt\n",
      "03686.txt\n",
      "03687.txt\n",
      "03688.txt\n",
      "03689.txt\n",
      "03690.txt\n",
      "03691.txt\n",
      "03692.txt\n",
      "03693.txt\n",
      "03694.txt\n",
      "03695.txt\n",
      "03696.txt\n",
      "03697.txt\n",
      "03698.txt\n",
      "03699.txt\n",
      "03700.txt\n",
      "03701.txt\n",
      "03702.txt\n",
      "03703.txt\n",
      "03704.txt\n",
      "03705.txt\n",
      "03706.txt\n",
      "03707.txt\n",
      "03708.txt\n",
      "03709.txt\n",
      "03710.txt\n",
      "03711.txt\n",
      "03712.txt\n",
      "03713.txt\n",
      "03714.txt\n",
      "03715.txt\n",
      "03716.txt\n",
      "03717.txt\n",
      "03718.txt\n",
      "03719.txt\n",
      "03720.txt\n",
      "03721.txt\n",
      "03722.txt\n",
      "03723.txt\n",
      "03724.txt\n",
      "03725.txt\n",
      "03726.txt\n",
      "03727.txt\n",
      "03728.txt\n",
      "03729.txt\n",
      "03730.txt\n",
      "03731.txt\n",
      "03732.txt\n",
      "03733.txt\n",
      "03734.txt\n",
      "03735.txt\n",
      "03736.txt\n",
      "03737.txt\n",
      "03738.txt\n",
      "03739.txt\n",
      "03740.txt\n",
      "03741.txt\n",
      "03742.txt\n",
      "03743.txt\n",
      "03744.txt\n",
      "03745.txt\n",
      "03746.txt\n",
      "03747.txt\n",
      "03748.txt\n",
      "03749.txt\n",
      "03750.txt\n",
      "03751.txt\n",
      "03752.txt\n",
      "03753.txt\n",
      "03754.txt\n",
      "03755.txt\n",
      "03756.txt\n",
      "03757.txt\n",
      "03758.txt\n",
      "03759.txt\n",
      "03760.txt\n",
      "03761.txt\n",
      "03762.txt\n",
      "03763.txt\n",
      "03764.txt\n",
      "03765.txt\n",
      "03766.txt\n",
      "03767.txt\n",
      "03768.txt\n",
      "03769.txt\n",
      "03770.txt\n",
      "03771.txt\n",
      "03772.txt\n",
      "03773.txt\n",
      "03774.txt\n",
      "03775.txt\n",
      "03776.txt\n",
      "03777.txt\n",
      "03778.txt\n",
      "03779.txt\n",
      "03780.txt\n",
      "03781.txt\n",
      "03782.txt\n",
      "03783.txt\n",
      "03784.txt\n",
      "03785.txt\n",
      "03786.txt\n",
      "03787.txt\n",
      "03788.txt\n",
      "03789.txt\n",
      "03790.txt\n",
      "03791.txt\n",
      "03792.txt\n",
      "03793.txt\n",
      "03794.txt\n",
      "03795.txt\n",
      "03796.txt\n",
      "03797.txt\n",
      "03798.txt\n",
      "03799.txt\n",
      "03800.txt\n",
      "03801.txt\n",
      "03802.txt\n",
      "03803.txt\n",
      "03804.txt\n",
      "03805.txt\n",
      "03806.txt\n",
      "03807.txt\n",
      "03808.txt\n",
      "03809.txt\n",
      "03810.txt\n",
      "03811.txt\n",
      "03812.txt\n",
      "03813.txt\n",
      "03814.txt\n",
      "03815.txt\n",
      "03816.txt\n",
      "03817.txt\n",
      "03818.txt\n",
      "03819.txt\n",
      "03820.txt\n",
      "03821.txt\n",
      "03822.txt\n",
      "03823.txt\n",
      "03824.txt\n",
      "03825.txt\n",
      "03826.txt\n",
      "03827.txt\n",
      "03828.txt\n",
      "03829.txt\n",
      "03830.txt\n",
      "03831.txt\n",
      "03832.txt\n",
      "03833.txt\n",
      "03834.txt\n",
      "03835.txt\n",
      "03836.txt\n",
      "03837.txt\n",
      "03838.txt\n",
      "03839.txt\n",
      "03840.txt\n",
      "03841.txt\n",
      "03842.txt\n",
      "03843.txt\n",
      "03844.txt\n",
      "03845.txt\n",
      "03846.txt\n",
      "03847.txt\n",
      "03848.txt\n",
      "03849.txt\n",
      "03850.txt\n",
      "03851.txt\n",
      "03852.txt\n",
      "03853.txt\n",
      "03854.txt\n",
      "03855.txt\n",
      "03856.txt\n",
      "03857.txt\n",
      "03860.txt\n",
      "03861.txt\n",
      "03863.txt\n",
      "03864.txt\n",
      "03865.txt\n",
      "03867.txt\n",
      "03868.txt\n",
      "03869.txt\n",
      "03870.txt\n",
      "03872.txt\n",
      "03873.txt\n",
      "03874.txt\n",
      "03875.txt\n",
      "03876.txt\n",
      "03877.txt\n",
      "03879.txt\n",
      "03880.txt\n",
      "03881.txt\n",
      "03882.txt\n",
      "03891.txt\n",
      "03892.txt\n",
      "03893.txt\n",
      "03894.txt\n",
      "03895.txt\n",
      "03896.txt\n",
      "03897.txt\n",
      "03913.txt\n",
      "03919.txt\n",
      "03920.txt\n",
      "03921.txt\n",
      "03922.txt\n",
      "03923.txt\n",
      "03924.txt\n",
      "03925.txt\n",
      "03926.txt\n",
      "03927.txt\n",
      "03928.txt\n",
      "03929.txt\n",
      "03930.txt\n",
      "03931.txt\n",
      "03932.txt\n",
      "03934.txt\n",
      "03935.txt\n",
      "03936.txt\n",
      "03937.txt\n",
      "03938.txt\n",
      "03939.txt\n",
      "03940.txt\n",
      "03941.txt\n",
      "03942.txt\n",
      "03943.txt\n",
      "03944.txt\n",
      "03945.txt\n",
      "03946.txt\n",
      "03947.txt\n",
      "03948.txt\n",
      "03949.txt\n",
      "03950.txt\n",
      "03951.txt\n",
      "03952.txt\n",
      "03953.txt\n",
      "03954.txt\n",
      "03955.txt\n",
      "03956.txt\n",
      "03957.txt\n",
      "03958.txt\n",
      "03959.txt\n",
      "03960.txt\n",
      "03961.txt\n",
      "03962.txt\n",
      "03963.txt\n",
      "03964.txt\n",
      "03965.txt\n",
      "03966.txt\n",
      "03967.txt\n",
      "03968.txt\n",
      "03969.txt\n",
      "03970.txt\n",
      "03971.txt\n",
      "03972.txt\n",
      "03973.txt\n",
      "03974.txt\n",
      "03975.txt\n",
      "03976.txt\n",
      "03977.txt\n",
      "03978.txt\n",
      "03979.txt\n",
      "03980.txt\n",
      "03981.txt\n",
      "03982.txt\n",
      "03983.txt\n",
      "03984.txt\n",
      "03985.txt\n",
      "03986.txt\n",
      "03991.txt\n",
      "03992.txt\n",
      "03993.txt\n",
      "03994.txt\n",
      "03995.txt\n",
      "03996.txt\n",
      "03997.txt\n",
      "03998.txt\n",
      "03999.txt\n",
      "04000.txt\n",
      "06001.txt\n",
      "06002.txt\n",
      "06003.txt\n",
      "06004.txt\n",
      "06005.txt\n",
      "06006.txt\n",
      "06007.txt\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from kitlvTdm import *\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import requests\n",
    "\n",
    "\n",
    "directory = 'Corpus'\n",
    "regex = r'((molukker\\\\w*)|(moluks\\\\w*)|(ambonn?ees\\\\w*)|((ambonn?ezen))|(menadonees(ch)?)|(menadonezen?)|(minahasa))'\n",
    "\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/peterverhaar/soldaat-in-indonesie/master/geweld.txt\"\n",
    "\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    response.encoding = 'utf-8' \n",
    "    \n",
    "violence = re.split('\\s+' , response.text )\n",
    "\n",
    "\n",
    "ranking = dict()\n",
    "page = dict()\n",
    "book = dict()\n",
    "wordsDict = dict()\n",
    "fullText = dict()\n",
    "\n",
    "fileIds = open( 'fileId2s.txt' , 'w')\n",
    "\n",
    "for file in os.listdir( directory ):\n",
    "    if file.endswith(\".txt\"):\n",
    "        print(file)\n",
    "        pageNr = 0\n",
    "        paragraphCount = 0\n",
    "\n",
    "\n",
    "        length = 0\n",
    "        text = open(os.path.join( directory , file))\n",
    "        for paragraph in text:\n",
    "            paragraphCount += 1\n",
    "            if re.search( '^page' , paragraph ):\n",
    "                ## keep track of pagenumbers\n",
    "                pageNr = paragraph.strip()\n",
    "                pageNr = re.sub( '^page\\s+' , '' , pageNr )\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                if re.search( regex , paragraph , re.IGNORECASE ):\n",
    "\n",
    "                    ## which ethnic group?\n",
    "                    match = re.search( regex , paragraph , re.IGNORECASE )\n",
    "                    found = match.group(1).lower()\n",
    "                    text = paragraph\n",
    "\n",
    "\n",
    "\n",
    "                    freq = dict()\n",
    "                    words = tokenise(paragraph)\n",
    "                    count = 0\n",
    "                    for w in words:\n",
    "                        if w.lower() in violence:\n",
    "                            freq[w] = freq.get( w , 0 ) +1\n",
    "                            count += 1\n",
    "\n",
    "\n",
    "\n",
    "                            if len(words) > 50:\n",
    "                                frId =  file + '-' + str(paragraphCount)\n",
    "                                fileIds.write( frId + '\\n')\n",
    "                                fullText[ frId ] = text\n",
    "                            \n",
    "                                ranking[ frId ] = len(freq) /  len(words)\n",
    "                                page[ frId ] = pageNr\n",
    "                                book[ frId ] = file\n",
    "\n",
    "                                wordsList = ''\n",
    "                                for w in freq:\n",
    "                                    wordsList += '{} ({}) ; '.format( w , freq[w] )\n",
    "                                wordsList = re.sub( ';\\s+$' , '' , wordsList )\n",
    "                                wordsDict[ frId ] = wordsList\n",
    "\n",
    "                        paragraph = ''\n",
    "                        length = 0\n",
    "\n",
    "\n",
    "out = open( 'gevondenPassages.txt' , 'w' , encoding = 'utf-8' )\n",
    "\n",
    "\n",
    "sorted_f = sorted( ranking , key=lambda x: ranking[x])\n",
    "\n",
    "for f in reversed( sorted_f ) :\n",
    "    bookId = re.sub( '[.]txt' , '' , f)\n",
    "    bookId = bookId.split('-')[0]\n",
    "    if ranking[f] > 0.01:\n",
    "        out.write( bookId  + '. ' + showTitle( book[f] ) )\n",
    "        out.write( ', pagina ' + page[f] + '\\n' )\n",
    "        out.write( fullText[f].strip() + '\\n' + wordsDict[f] + '\\n' )\n",
    "        out.write( str( ranking[f] ) + '\\n\\n' )\n",
    "\n",
    "\n",
    "out.close()\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
